---
title: "Linear Regression"
format: gfm
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(paged.print = FALSE)
```

```{r}
#| message: false
library(data.table)
```

# Using Linear Regression

## Intro PUMS dataset

For this task, you will use the 2016 US Census PUMS dataset. For simplicity, we have prepared a small sample of PUMS data to use for this example. The data preparation steps include these: - Restricting the data to full-time employees between 20 and 50 years of age, with an income between \$1,000 and \$250,000. - Dividing the data into a training set, dtrain, and a test set, dtest.

```{r}
psub <- readRDS("repo-clone/PUMS/psub.RDS")
names(psub)
```

```{r}
set.seed(3454351)
psub$gp <- runif(nrow(psub))
dtrain <- subset(psub, gp >= 0.5)
dtest <- subset(psub, gp < 0.5)
nrow(psub); nrow(dtrain); nrow(dtest)
```

```{r}
model <- lm(log10(PINCP) ~ AGEP + SEX + COW + SCHL, data = dtrain)
dtest$predLogPINCP <- predict(model, newdata = dtest)
dtrain$preLogPINCP <- predict(model, newdata = dtrain)
```

Fitting logarithm-transformed data typically gives results with smaller relative error, emphasizing smaller errors on smaller incomes. But this improved relative error comes at a cost of introducing a bias: on average, predicted incomes are going to be below actual training incomes. An unbiased alternative to predicting log(income) would be to use a type of generalized linear model called Poisson regression. We will discuss generalized linear models (specifically, logistic regression) in section 7.2. The Poisson regression is unbiased, but typically at the cost of larger relative errors.

## Prediction quality

```{r pracdsr-linreg-1}
library(ggplot2)
ggplot(dtest, aes(x = predLogPINCP, y = log10(PINCP))) +
  geom_point(alpha = 0.2, color = "grey80") +
  geom_smooth(color = "darkblue") +
  geom_line(aes(x = log10(PINCP), y = log10(PINCP)),
                color = "black", linetype = 2) +
  coord_cartesian(xlim = c(4, 5.25),
                  ylim = c(3.5, 5.5))


```

Residual plot

```{r pracdsr-linreg-2}
ggplot(dtest, aes(x = predLogPINCP, y = predLogPINCP - log10(PINCP))) +
  geom_point(alpha = 0.2, color = "grey50") +
  geom_smooth(color = "darkgreen") +
  ylab("residual error (prediction - actual)")
```

Considerations of residual plots

1.  Are predictions correct on average?

Does the smoothing curve lie more or less along the line of perfect prediction? Ideally, the points will all lie very close to that line, but you may instead get a wider cloud of points (as we do in figures 7.6 and 7.7) if your input variables don’t explain the output too closely. But if the smoothing curve lies along the line of perfect prediction and “down the middle” of the cloud of points, then the model predicts correctly on average: it underpredicts about as much as it overpredicts.

2.  Are there systematic errors?

If the smoothing curve veers off the line of perfect prediction too much, as in figure 7.8, this is a sign of systematic under or overprediction in certain ranges: the error is correlated with the prediction. Systematic errors indicate that the system is not “linear enough” for a linear model to be a good fit, so you should try one of the different modeling approaches that we will discuss later in this book.

3.  R-squared and RMSE

```{r}
rsq <- function(y, f) {1 - sum((y - f)^2)/sum((y - mean(y))^2)}

rsq(log10(dtrain$PINCP), dtrain$preLogPINCP)
rsq(log10(dtest$PINCP), dtest$predLogPINCP)
```

For well-fit models, R-squared is also equal to the square of the correlation between the predicted values and actual training values.

```{r}
cor(log10(dtrain$PINCP), dtrain$preLogPINCP)^2
mod_sum <- summary(model)
mod_sum$r.squared; mod_sum$adj.r.squared
```

```{r}
rmse <- function(y, f) { sqrt(mean((y - f)^2)) }
rmse(log10(dtrain$PINCP), dtrain$preLogPINCP)
rmse(log10(dtest$PINCP), dtest$predLogPINCP)
```

## Finding relations and extracting advice

```{r}
coefficients(model)
```

Someone with a bachelor's degree earns on average 2.3 times more than someone without a HS diploma and 1.8 times more than someone with a HS diploma.

```{r}
10^.3637
10^(.3637 - .1135)
```

The intercept

In our example, the reference subject would be a male employee of a private for-profit company, with no high school degree, who is zero years old. If such a person could exist, the model would predict their log base 10 income to be about 4.0, which corresponds to an income of \$10,000.

## Reliability/quality of coefficients

> formula

```{r}
summary(model)$call
```

> residuals

```{r}
summary(summary(model)$residuals)
```

```{r}
(resids_train <- summary(log10(dtrain$PINCP) - 
                           predict(model, newdata = dtrain)))
(resids_test <- summary(log10(dtest$PINCP) - 
                           predict(model, newdata = dtest)))
```

Looking for a median near 0 and 1st and 3rd quantiles roughly equidistant from the median.

> coefficients

```{r}
options(digits = 6)
summary(model)$coefficients
```

In terms of prediction (our primary goal), it’s not a problem to have a small number of insignificant coefficients with small effects sizes. Problems arise when we have insignificant coefficients with large coefficients/effects or a great number of insignificant coefficients.

Signs of potential collinearity between variables - removal of an insignificant variable increases the significance of another - unreasonably large coefficients or ses - unexpected signs on coefficients

> Degrees of freedom

Note that for test data, the df is equal to the number of rows.

```{r}
summary(model)$df
(df <- nrow(dtrain) - nrow(summary(model)$coefficients))
```

> Residual standard error

```{r}
sqrt(sum(residuals(model)^2) / df)
sqrt(sum(mod_sum$residuals^2) / mod_sum$df[[2]])
```

